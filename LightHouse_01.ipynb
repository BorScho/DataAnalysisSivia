{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(Example from the Book p.29 ff)\n",
    "\n",
    "A lighthouse is somewhere off a piece of straight coastline at a position α (alpha) along the shore and a distance <br>\n",
    "β (beta) out at sea. It emits a series of short highly collimated flashes at random intervals and hence at random azimuths. <br>\n",
    "These pulses are intercepted on the coast by photo-detectors that record only the fact that a flash has occurred, but not <br>\n",
    "the angle from which it came. <br>\n",
    "N flashes have so far been recorded at positions {xk}. Where is the lighthouse?’\n",
    "\n",
    "<img src=\"pictures01/lightHouseGeometry.jpg\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-1.18027881 -0.33207798  0.64961123 -1.4043952  -0.73957294  0.56570059\n",
      "  1.4381734   0.9824136   0.84808338 -0.67753555]\n",
      "[ -8.71675638  -0.3793932    4.03836457 -22.81602052  -2.64922689\n",
      "   3.53967762  30.98365863   6.99506125   5.53576839  -2.21837373]\n"
     ]
    }
   ],
   "source": [
    "# generate data to analyze:\n",
    "import numpy as np\n",
    "\n",
    "# position of light-house on x-axis:\n",
    "alpha = 1\n",
    "\n",
    "# position of light-house off shore:\n",
    "beta = 4\n",
    "\n",
    "def data_from_angle(thetas, alpha, beta):\n",
    "    return beta * np.tan(thetas) + alpha\n",
    "\n",
    "def generate_data(numberOfDataPoints = 10):\n",
    "    return np.random.uniform(size=numberOfDataPoints, low=-np.pi/2, high=np.pi/2)\n",
    "\n",
    "# test functions:\n",
    "theta_ks = generate_data()\n",
    "print(theta_ks)\n",
    "\n",
    "x_ks = data_from_angle(thetas=theta_ks, alpha=alpha, beta=beta)\n",
    "print(x_ks)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we assume a uniform distribution, $ prob(\\theta | \\{x_k\\}, \\alpha, \\beta, I) = \\frac{1}{\\pi}$ for $\\theta$ between $[- \\pi/2 , + \\pi/2]$, we have a Cauchy-Distribution vor the $x_k$ :\n",
    "\n",
    "$$\n",
    "prob(x_k | \\alpha, \\beta, I) = \\frac{\\beta}{\\pi [\\beta^2 + (x_k - \\alpha)^2]}\n",
    "$$\n",
    "\n",
    "Using Bayes' theorem and assuming independence for the measurements, the log-prob function L is given by:\n",
    "\n",
    "$$\n",
    "  L = log(prob(  \\alpha, \\beta | \\{x_k\\} , I) = const + \\sum^N_{k=1}{(log(\\beta) - log(\\beta^2 + (x_k - \\alpha)^2))}\n",
    "$$\n",
    "\n",
    "To find our best estimate for $\\alpha$ and $\\beta$ we take partial derivatives equal zero and thus end up with a non-liniear optimization problem / non-linear root finding problem that we will have to solve numerically:\n",
    "\n",
    "$$\n",
    "\\frac{\\partial L}{\\partial \\alpha} = \\sum^N_{k=1}{\\frac{2 (x_k - \\alpha)}{\\beta^2 + (x_k - \\alpha)^2}} = 0 \\\\\n",
    "\n",
    "\n",
    "\\frac{\\partial L}{\\partial \\beta} = \\frac{N}{\\beta} - \\sum^N_{k=1}{\\frac{2 \\beta}{\\beta^2 + (x_k - \\alpha)^2}} = 0\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.210739197207331e-06"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def gradient_descent(gradient_f, start, learn_rate, n_iter=50, tolerance=1e-06):\n",
    "    vector = start\n",
    "    for _ in range(n_iter):\n",
    "        diff = -learn_rate * gradient_f(vector)\n",
    "        if np.all(np.abs(diff) <= tolerance):\n",
    "            break\n",
    "        vector += diff\n",
    "    return vector\n",
    "\n",
    "# test of function for f(x)=X**2:\n",
    "\n",
    "gradient_descent(gradient_f=lambda x: 2*x, start=10, learn_rate=0.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2.2107392e-06, 2.2107392e-06])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test of function for f(x, y)= ( x**2 , y**2 + 1):\n",
    "\n",
    "def grad_f(x):\n",
    "    return np.array([2*x[0], 2*x[1]])\n",
    "\n",
    "gradient_descent(gradient_f=grad_f, start=np.array([10.0, 10.0]), learn_rate=0.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TO DO: use numpy operations everywhere:\n",
    "def dL_da(start, x_ks):\n",
    "    x_minus_a = x_ks - start[0]\n",
    "    numerator = 2 * x_minus_a\n",
    "    denominator = start[1]**2 + x_minus_a**2\n",
    "    fractions = numerator/denominator\n",
    "    return np.sum(fractions)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TO DO: use numpy operations everywhere:\n",
    "def dL_db(start, x_ks):\n",
    "    N = np.size(x_ks)\n",
    "    x_minus_a = x_ks - start[0]\n",
    "    numerator = 2 * start[1]\n",
    "    denominator = start[1]**2 + x_minus_a**2\n",
    "    fractions = numerator/denominator\n",
    "    return N/start[1] - np.sum(fractions)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_L(start, x_ks):\n",
    "    return np.array([dL_da(start, x_ks), dL_db(start, x_ks)])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "condaPytorchEnv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
